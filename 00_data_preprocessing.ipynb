{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihatami1998/MachineLearning/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOw8yMd1VlnD"
      },
      "source": [
        "# Data Preprocessing Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvUGC8QQV6bV"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfFEXZC0WS-V"
      },
      "source": [
        "# importing necessary libraries \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Dataset"
      ],
      "metadata": {
        "id": "SAvJ10j4YIgs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqHTg9bxWT_u"
      },
      "source": [
        "# reading the dataset \n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Data.csv')\n",
        "\n",
        "# independent variables\n",
        "X = dataset.iloc[:, :-1].values\n",
        "\n",
        "# dependant variable\n",
        "Y = dataset.iloc[:,-1].values"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsxp1OKNE6tO",
        "outputId": "c72db9ca-33e4-45f6-dbff-d85057f53929"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV-AOgN8E7BS",
        "outputId": "3868b164-bb2a-494d-9067-323626d61514"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmt1BcYfIYQM"
      },
      "source": [
        "## Taking Care of the Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we use scikit-learn to handle the missing data\n",
        "# apply this object to our matrix of features\n",
        "\n",
        "# from impute module of sklearn library, import SimpleImputer class\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# create an object(instance) from this class and call the class on that variable\n",
        "# we can use different strategies to fill nan values: 'mean', 'median', 'most_frequent', 'constant'\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# now we should apply this object to our matrix of features\n",
        "# we use a method of 'imputer' class called 'fit'\n",
        "# we give only the numerical features of our X matrix as input to the 'fit' method\n",
        "imputer.fit(X[:, 1:3])\n",
        "\n",
        "# now to do the replacement we need to use another method of 'imputer' class called 'transform'\n",
        "# input of 'transform' method should be same as the input of 'fit' method\n",
        "# 'transform' method returns the new updated version of feature matrix X with replacements of missing data\n",
        "X[:, 1:3] =imputer.transform(X[:, 1:3])"
      ],
      "metadata": {
        "id": "chJ_2FhLIhAl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjJ1FWOJLLTD",
        "outputId": "b160ccdd-1fd5-41e0-a73c-8bcbda2c56d5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the Categorical dData"
      ],
      "metadata": {
        "id": "5tGHKvUeRY4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we use one-hot encoding to transform categorical data into numerical data\n",
        "# we will need 'ColumnTransformer' class from 'compose' module of sklearn\n",
        "# we will need 'OneHotEncoder' class from 'preprocessing' module of sklearn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# then we should make objects from those classes with some arguments\n",
        "# for the 'transformer' argument we have to specify a tupple including: 1. kind of transformation(encoding here),\n",
        "# 2. kind of encoding class(one-hot encoding here), 3. indexes of the column we want to encode(country here)\n",
        "\n",
        "# for the 'remainder' arguement we give value of 'passthrough', to keep the other columns that we don't want encoding being applied on.\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])],\n",
        "                       remainder='passthrough')\n",
        "\n",
        "# so far we've created the 'ct' object, now we should connect it to our feature matrix X\n",
        "# we call 'fit_transform' method of 'ct' object on matrix X and this creates a new matrix X\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "# the output of 'ct.fit_transofrm(x)' is a matrix, but for later training the ML models, we need it to be a Numpy array, so change it now.\n",
        "\n"
      ],
      "metadata": {
        "id": "gKI9itnqQLMA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN1O0aebWn6Y",
        "outputId": "1d6e5616-52bd-4d23-d83c-3b9b50681dad"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the Dependent Variable"
      ],
      "metadata": {
        "id": "nZAaccDLX7Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we should do another encoding transformation for the dependant variable because it has text format\n",
        "# because it has only 'Yes', and 'No' values, we use another encoder class named 'LabelEncoder'\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# unlike the X matrix, the Y vector doesn't need to be a Numpy Array in our future ML work. so we don't change this one here."
      ],
      "metadata": {
        "id": "tP9x1_IZYLr_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upgC3qHnZX7X",
        "outputId": "d1adf1fa-bc8f-4c4c-bb45-f257f6cb3c39"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXY3zdL3P6Mp"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to split our dataset we use 'train_test_split' function from 'model_selection' module from 'sklearn' library\n",
        "# this function creates 4 separate sets, two pairs of matrix of feature and dependant variable for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# since we know what this function will return, we name these 4 variables as what this function returns\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "NuePFvNveruv"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNOTz_p0g8rn",
        "outputId": "e0b4265b-d023-47ca-ce17-a00907f752e5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 37.0 67000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4rTpOvekKJI",
        "outputId": "237e89cf-b50f-49c2-f3c8-90e16982afa9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4MmBlK-kQVf",
        "outputId": "0da16b6e-1d97-46b7-e33b-0f35824acaa2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bguex5gIkSyx",
        "outputId": "0e74f14e-f1ac-4f83-de66-15085a4d8e53"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling"
      ],
      "metadata": {
        "id": "wLRVJddJbUMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to apply feature scaling we use 'StandardScalar' class from the same 'preprocessing' module from 'sklearn' library\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# now we should create an object(instance) of this class\n",
        "sc = StandardScaler()\n",
        "\n",
        "# now we should call 'fit_transform' method on this object\n",
        "X_train = sc.fit_transform(X_train)\n",
        "\n",
        "# this method keeps the matrix X as a Numpy array, so we don't need to convert it ourself\n"
      ],
      "metadata": {
        "id": "81C4YiDYbWQe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFk1itsbeIqv",
        "outputId": "5f733079-5f31-4e4e-ae70-abd2b6538b58"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.          2.64575131 -0.77459667  0.26306757  0.12381479]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.25350148  0.46175632]\n",
            " [-1.         -0.37796447  1.29099445 -1.97539832 -1.53093341]\n",
            " [-1.         -0.37796447  1.29099445  0.05261351 -1.11141978]\n",
            " [ 1.         -0.37796447 -0.77459667  1.64058505  1.7202972 ]\n",
            " [-1.         -0.37796447  1.29099445 -0.0813118  -0.16751412]\n",
            " [ 1.         -0.37796447 -0.77459667  0.95182631  0.98614835]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.59788085 -0.48214934]]\n"
          ]
        }
      ]
    }
  ]
}
